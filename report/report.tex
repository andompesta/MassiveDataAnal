\documentclass{acm_proc_article-sp-sigmod07}

\usepackage{times}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{color}
\usepackage{url}
\usepackage{mathtools}
\usepackage{amsfonts}
\usepackage{newclude}
\usepackage{float}
\usepackage{listings}
\usepackage{caption}
%\usepackage[toc,page]{appendix}

%\usepackage{hyperref}
% Pacchetti per poter scrivere con la tastiera italiana
\usepackage{ucs}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc} %Aumenta la resa dei caratteri quando si stampa

% Pacchetto per scrivere in italiano
\usepackage[english]{babel}

% Pacchetti matematici vari
% Pacchetti base

\usepackage{makeidx} % Pacchetto per l'indice analitico
\usepackage{mparhack} % Pacchetto che corregge alcuni errori nei magini della pagina 
\usepackage{marginnote} % Pacchetto che permette di scrivere note a margine 
\usepackage{listings} % Pacchetto necessario per scrivere codice sorgente 
\usepackage{braket} % Pacchetto che permette di scrivere tutte le parentesi
\usepackage{csquotes}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{changepage}
\usepackage{cite}
\usepackage[english]{varioref}

\usepackage[letterpaper]{geometry}
\geometry{top=1.0in, bottom=1.0in, left=1.0in, right=1.0in}

\lstdefinestyle{customc}{
  belowcaptionskip=1\baselineskip,
  breaklines=true,
  frame=L,
  xleftmargin=\parindent,
  language=C,
  showstringspaces=false,
  basicstyle=\footnotesize\ttfamily,
  keywordstyle=\bfseries\color{blue},
  commentstyle=\itshape\color{green},
  identifierstyle=\color{black},
  stringstyle=\color{orange},
}

\lstdefinestyle{customasm}{
  belowcaptionskip=1\baselineskip,
  frame=L,
  xleftmargin=\parindent,
  language=[x86masm]Assembler,
  basicstyle=\footnotesize\ttfamily,
  commentstyle=\itshape\color{purple!40!black},
}

\lstset{escapechar=@,style=customc}


\begin{document}
\title{Event summarization from news and tweets correlation}
\author{Cavallari Sandro\\Giglio Marco\\Morettin Paolo}

%
\maketitle
\begin{abstract}
In this report we consider the task of extracting a summary of the main event
that caused a shift on the opinion of Twitter users. This paper presents
several techniques which might be used to analyze these \emph{sentiment shift}
and to find the event which caused them. For each technique presented below
some aspects are taken in account, which are important in the context of a data
mining application, such as scalability and efficiency. A comparison of the
different techniques is showed as well.\end{abstract}   

\section*{Introduction}
This work aims to find a summary of the events which caused a\emph{sentiment shift}. 

While event extraction NLP technique are mature, their performance on tweets inevitably degrades due to the inherent sparsity in short texts.  Since tweets contain heterogeneous language structures and are at most 140 characters long, to extract event from tweets is quite tricky: instead linking tweet to news allows us to extract events from news text that has a well formed structure and contains more text with respect to tweets.

Due to the fact that our dataset is composed by labelled tweets, we manage to extract news from the New York Times archive basing the research on tweet's label. Starting form a good Tweet-News classification, allowed us to correlate tweet and news that belong to the same macro-topics avoiding to correlate object of different arguments.

In particular document compression is one of the main topic in \emph{NLP} research field: usually this task is achieved using abstractive methods and language dependent technique.  Our work, rather, want to be as much as possible language independent, so we propose solutions for this problem using technique based on:
\begin{itemize}
	\item a simple \emph{bag of words} approach exploiting the \emph{SpaceSaving algorithm} \cite{SS}
	\item a Latent Semantic Indexing[LSI] that uses a SVD mathematical technique \cite{LSA}
	\item a N-Gram Graph[NGG] \cite{Ngram}
\end{itemize}


\section*{Related Work}
\include*{chapters/RelatedWork}

\section*{Problem Definition}
\include*{chapters/ProblemDefinition}

\section*{Proposed Approach}
\include*{chapters/ProposedApproach}

\section*{Experimental Evaluation}
\include*{chapters/ExperimentalEvaluation}

\section*{Conclusions}

\begin{thebibliography}{9}
\bibitem{LSA} 
	Indexing by Latent Semantic Analysis, Scott Deerwester , Susan T. Dumais*, George W. Furnas,  Thomas K. Landauer  and Richard Harshman 
\bibitem{Gensim}
  ŘEHŮŘEK, Radim, et al. ``\emph{Software framework for topic modelling with large corpora}''. 2010.
\bibitem{Ngram}
	Automatic Summarization from Multiple Documents : N-Gram Graph, George Giannakopoulos and Ncsr Demokritos, 2009
\bibitem{LTN}
	Linking Tweets to News: A Framework to Enrich Short Text Data in Social Media, Weiwei Guo, Hao Li, Heng Ji and Mona Diab
\bibitem{WTMF}
	Modeling Sentences in the Latent Space, Weiwei Guo and Mona Diab , 2012
\bibitem{MSC}
	Multi-Sentence Compression: Finding Shortest Paths in Word Graphs, Katja Filippova 
\bibitem{SS}
	Metwally A. et al, ``\emph{Efficient Computation of Frequent and Top-k
	Elements in Data Streams}'', Lecture Notes in Computer Science Volume 3363, 2005, pp 398-412

\end{thebibliography}
\end{document}
